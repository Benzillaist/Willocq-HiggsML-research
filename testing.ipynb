{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import Sequential\n",
    "from tensorflow import python as tf_python\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import scikitplot as skplt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal tree entries: 3319\n",
      "Background tree entries: 3531\n"
     ]
    }
   ],
   "source": [
    "#loads in files for signal and background\n",
    "file_sig = uproot.open(\"mc16e_signal.root\")\n",
    "file_back = uproot.open(\"mc16e_ttbar.root\")\n",
    "\n",
    "#Sets trees of files to variables\n",
    "tree_sig = file_sig[\"nominal\"]\n",
    "tree_back = file_back[\"nominal\"]\n",
    "\n",
    "#Prints number of entries for each tree\n",
    "print(f'Signal tree entries: {tree_sig.num_entries}')\n",
    "print(f'Background tree entries: {tree_back.num_entries}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows contents of each tree\n",
    "#tree_sig.show()\n",
    "#tree_back.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "muonStats_sig = tree_sig.arrays(['mu_pt', 'mu_eta', 'mu_phi'])\n",
    "jetStats_sig = tree_sig.arrays(['jet_pt', 'jet_eta', 'jet_phi'])\n",
    "muonStats_back = tree_back.arrays(['mu_pt', 'mu_eta', 'mu_phi'])\n",
    "jetStats_back = tree_back.arrays(['jet_pt', 'jet_eta', 'jet_phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109464.52   65954.625 148726.    ...  53041.37   58756.44   56119.04 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate(np.array(muonStats_sig['mu_pt']), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(np.concatenate(muonStats_sig['mu_pt'], axis = 0),bins=np.linspace(0,450000,101),label='Signal', histtype='step')\n",
    "#plt.hist(np.concatenate(muonStats_back['mu_pt'], axis = 0),bins=np.linspace(0,450000,101),label='Background', histtype='step')\n",
    "#plt.xlabel(r'Muon $p_{T}$ [GeV]')\n",
    "#plt.ylabel('Count')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mu_pt', 'mu_eta', 'mu_phi', 'ljet_pt', 'ljet_eta', 'ljet_phi', 'ljet_pt_cand', 'ljet_eta_cand', 'ljet_phi_cand']\n",
      "(                        mu_pt    mu_eta    mu_phi   ljet_pt_cand  \\\n",
      "entry subentry                                                     \n",
      "0     0         109464.523438  0.752634 -0.603566  274842.875000   \n",
      "1     0          65954.625000  0.954476  0.651902  212455.109375   \n",
      "2     0         148726.000000  1.510869 -0.182065  371398.625000   \n",
      "3     0          71516.101562  0.254257  2.440928  331628.312500   \n",
      "4     0         222168.671875  0.672102  0.522216  341838.843750   \n",
      "...                       ...       ...       ...            ...   \n",
      "3314  0          52193.957031  0.362391  2.417538  231281.109375   \n",
      "3315  0         146224.984375 -0.150667  0.455322  268928.281250   \n",
      "3316  0          53041.371094 -1.209407  1.332303  219864.437500   \n",
      "3317  0          58756.441406  0.259072  1.774282  221806.578125   \n",
      "3318  0          56119.039062 -0.593785  1.690351  293187.750000   \n",
      "\n",
      "                ljet_eta_cand  ljet_phi_cand  \n",
      "entry subentry                                \n",
      "0     0              0.760044      -0.542501  \n",
      "1     0              1.268582       0.635921  \n",
      "2     0              1.638378      -0.460992  \n",
      "3     0              0.299665       2.942886  \n",
      "4     0              0.488505       0.590382  \n",
      "...                       ...            ...  \n",
      "3314  0              0.386634       1.666222  \n",
      "3315  0             -0.224302       0.574036  \n",
      "3316  0             -1.570454       1.296174  \n",
      "3317  0              0.655477       1.674686  \n",
      "3318  0             -0.087748       1.399554  \n",
      "\n",
      "[3319 rows x 6 columns],                       ljet_pt  ljet_eta  ljet_phi\n",
      "entry subentry                                   \n",
      "0     0         274842.875000  0.760044 -0.542501\n",
      "1     0         212455.109375  1.268582  0.635921\n",
      "2     0         495089.531250  1.834779  2.764217\n",
      "      1         371398.625000  1.638378 -0.460992\n",
      "3     0         407043.968750  0.030081 -0.201683\n",
      "...                       ...       ...       ...\n",
      "3315  0         268928.281250 -0.224302  0.574036\n",
      "3316  0         219864.437500 -1.570454  1.296174\n",
      "3317  0         232007.484375  0.984181 -1.556253\n",
      "      1         221806.578125  0.655477  1.674686\n",
      "3318  0         293187.750000 -0.087748  1.399554\n",
      "\n",
      "[4692 rows x 3 columns])\n"
     ]
    }
   ],
   "source": [
    "print(tree_sig.keys(filter_name=\"/(ljet|mu)_(pt|eta|phi)/\"))\n",
    "allStats_sig = tree_sig.arrays(filter_name=\"/(ljet|mu)_(pt|eta|phi)/\", library = 'pd')\n",
    "allStats_back = tree_back.arrays(filter_name=\"/(ljet|mu)_(pt|eta|phi)/\", library = 'pd')\n",
    "muonStats_sig = allStats_sig[0];\n",
    "jetStats_sig = allStats_sig[1];\n",
    "muonStats_back = allStats_back[0];\n",
    "jetStats_back = allStats_back[1];\n",
    "\n",
    "print(allStats_sig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENSURE WEIGHTS ARE THE LAST ENTRY IN THE VAR ARRAY\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labelsFunc, useWeightObj = False, weightObj = 0, batch_size=32, dim=(14), n_channels=1, n_classes=2, shuffle=True):\n",
    "        self.dim = dim\n",
    "        self.useWeightObj = useWeightObj\n",
    "        self.weightObj = weightObj\n",
    "        self.batch_size = batch_size\n",
    "        self.labelsFunc = labelsFunc\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X[:, :-1], y, (X[:, -1])\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, self.dim,))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i] = np.load('data/' + str(ID) + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labelsFunc(ID)\n",
    "        \n",
    "        X[:, :-1] = StandardScaler().fit_transform(X[:, :-1])\n",
    "\n",
    "        if(self.useWeightObj):\n",
    "            X[:, -1] = X[:, -1] * [self.weightObj[i] for i in y]\n",
    "\n",
    "        return X, y #keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "\n",
    "#ENSURE WEIGHTS ARE THE LAST ENTRY IN THE VAR ARRAY\n",
    "def getList_ID(fileName, tree, varNames, max_entry = 10000):\n",
    "    df = pd.DataFrame()\n",
    "    opFile = uproot.open(fileName + ':' + tree)\n",
    "    for var in varNames:\n",
    "        varDf = opFile[var].array(entry_stop = max_entry, library = 'pd')\n",
    "        if(varDf.index.nlevels == 2):\n",
    "            df[var] = varDf.reset_index(level=1, drop=True)\n",
    "        else:\n",
    "            df[var] = varDf\n",
    "    df.filter(df['weight'] > 0)\n",
    "    saveArr = df.to_numpy()\n",
    "    savePrefix = fileName[:fileName.find('.')]\n",
    "    saveStrings = []\n",
    "    for i in range(saveArr.shape[0]):\n",
    "        saveString = savePrefix + str(i)\n",
    "        saveStrings.append(saveString)\n",
    "        np.save('data/' + saveString + '.npy', saveArr[i])\n",
    "    return saveStrings\n",
    "\n",
    "def create_heat_map(df):\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, \n",
    "    cmap='RdYlGn', \n",
    "    xticklabels=corr.columns.values,\n",
    "    yticklabels=corr.columns.values)\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(fit):\n",
    "    plt.plot(fit.history['loss'])\n",
    "    plt.plot(fit.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(fit):\n",
    "    plt.plot(fit.history['accuracy'])\n",
    "    plt.plot(fit.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def custom_LearningRate_schedular(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.01 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "    \n",
    "def get_model(metric, inputShape, bias):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(4, activation='relu', input_shape=inputShape, bias_initializer=keras.initializers.Constant(bias)),\n",
    "        # keras.layers.Dense(128, activation='relu'),\n",
    "        # keras.layers.Dense(128, activation='relu'),\n",
    "        # keras.layers.Dense(128, activation='relu'),\n",
    "        # keras.layers.Dense(128, activation='relu'),\n",
    "        # keras.layers.Dense(64, activation='relu'),\n",
    "        # keras.layers.Dense(64, activation='relu'),\n",
    "        # keras.layers.Dense(64, activation='relu'),\n",
    "        # keras.layers.Dense(64, activation='relu'),\n",
    "        # keras.layers.Dense(32, activation='relu'),\n",
    "        # keras.layers.Dense(8, activation='relu'),\n",
    "        #keras.layers.Dense(4, activation='relu'),\n",
    "        #tf.keras.layers.Dense(units=2, activation='softmax')\n",
    "        keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(\n",
    "                        name='binary_crossentropy'),\n",
    "                metrics=[metric])\n",
    "    # model.layers[0].bias.assign([bias])\n",
    "    return model\n",
    "\n",
    "def boosted_decision_tree():\n",
    "    model = tfdf.keras.GradientBoostedTreesModel()\n",
    "    return model\n",
    "\n",
    "def create_tensor_object(train_variables,dict):\n",
    "    df = pd.DataFrame()\n",
    "    key = list(dict.keys())[0]\n",
    "    print(\"key: \" + key)\n",
    "    for var in train_variables:\n",
    "        if var == \"classification\":\n",
    "            continue\n",
    "        else:\n",
    "            print(\"var: \" + var)\n",
    "            print(dict[key])\n",
    "            print(dict[key][var])\n",
    "            print(np.array(dict[key][var].array(library = 'pd')))\n",
    "            #df[var] = np.array(dict[key][var].array())\n",
    "    if \"signal\" in key:\n",
    "        print(\"SIGNAL CLASSIFICATION SET TO 1\", key)\n",
    "        df.insert(0, 'classification', 1)\n",
    "    else:\n",
    "        print(\"BACKGROUND CLASSIFICATION SET TO 0\", key)\n",
    "        df.insert(0, 'classification', 0)\n",
    "    \n",
    "    #split the data into train and testing set\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "    \n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "    \n",
    "    train_df.filter(train_df['weight'] > 0)\n",
    "    test_df.filter(test_df['weight'] > 0)\n",
    "    val_df.filter(val_df['weight'] > 0)\n",
    "    \n",
    "    train_df_class = train_df.pop('classification')\n",
    "    train_df_weights = train_df.pop('weight')\n",
    "    test_df_class = test_df.pop('classification')\n",
    "    test_df_weights = test_df.pop('weight')\n",
    "    val_df_class = val_df.pop('classification')\n",
    "    val_df_weights = val_df.pop('weight')\n",
    "\n",
    "    #create heat map of training variables\n",
    "    hmap = create_heat_map(train_df)\n",
    "    \n",
    "    return train_df, train_df_class, train_df_weights, test_df, test_df_class, test_df_weights, val_df, val_df_class, val_df_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_object(train_variables,dict):\n",
    "    df = pd.DataFrame()\n",
    "    key = list(dict.keys())[0]\n",
    "    print(\"key: \" + key)\n",
    "    for i in range(len(train_variables)):\n",
    "        var = train_variables[i];\n",
    "        if(var == 'classification'):\n",
    "            continue\n",
    "        else:\n",
    "            df.insert(len(df.columns), var, dict[key][var].array(library = 'pd'))\n",
    "\n",
    "    if \"signal\" in key:\n",
    "        print(\"SIGNAL CLASSIFICATION SET TO 1\", key)\n",
    "        df.insert(0, 'classification', 1)\n",
    "    else:\n",
    "        print(\"BACKGROUND CLASSIFICATION SET TO 0\", key)\n",
    "        df.insert(0, 'classification', 0)\n",
    "    \n",
    "    #split the data into train and testing set\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "    \n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "    \n",
    "    train_df.filter(train_df['weight'] > 0)\n",
    "    test_df.filter(test_df['weight'] > 0)\n",
    "    val_df.filter(val_df['weight'] > 0)\n",
    "    \n",
    "    train_df_class = train_df.pop('classification')\n",
    "    train_df_weights = train_df.pop('weight')\n",
    "    test_df_class = test_df.pop('classification')\n",
    "    test_df_weights = test_df.pop('weight')\n",
    "    val_df_class = val_df.pop('classification')\n",
    "    val_df_weights = val_df.pop('weight')\n",
    "\n",
    "    #create heat map of training variables\n",
    "    hmap = create_heat_map(train_df)\n",
    "    \n",
    "    return train_df, train_df_class, train_df_weights, test_df, test_df_class, test_df_weights, val_df, val_df_class, val_df_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: signal_e\n",
      "SIGNAL CLASSIFICATION SET TO 1 signal_e\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_variables = ['mupt_cand', 'mueta_cand', 'muphi_cand', 'ljet_pt_cand', 'ljet_eta_cand',\\\n",
    "#                   'ljet_phi_cand', 'ljet_mass_cand', 'dR_values_cand', 'pt_higgs',\\\n",
    "#                   'mass_T', 'met_met', 'met_phi', 'mass_mj', 'weight']\n",
    "\n",
    "train_variables = ['classification','dR_values_cand','pt_higgs','mass_T', 'mass_mj', 'weight']\n",
    "\n",
    "signal_train_e, signal_train_class_e, signal_train_weights_e, signal_test_e, signal_test_class_e, signal_test_weights_e, signal_val_e, signal_val_class_e, signal_val_weights_e = create_tensor_object(train_variables, {\"signal_e\" : tree_sig})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_entries = 10000\n",
    "\n",
    "train_variables = ['mupt_cand', 'mueta_cand', 'muphi_cand', 'ljet_pt_cand', 'ljet_eta_cand',\\\n",
    "                   'ljet_phi_cand', 'ljet_mass_cand', 'dR_values_cand', 'pt_higgs',\\\n",
    "                   'mass_T', 'met_met', 'met_phi', 'mass_mj', 'weight']\n",
    "\n",
    "signalMatrix = getList_ID('mc16e_signal.root', 'nominal', train_variables, max_entry = max_entries)\n",
    "signalLabels = np.ones(shape = len(signalMatrix))\n",
    "\n",
    "ttbarMatrix = getList_ID('mc16e_ttbar.root', 'nominal', train_variables, max_entry = max_entries)\n",
    "ttbarLabels = np.zeros(shape = len(ttbarMatrix))\n",
    "\n",
    "mixedMatrix = np.concatenate((signalMatrix, ttbarMatrix))\n",
    "mixedLabels = np.concatenate((signalLabels, ttbarLabels))\n",
    "\n",
    "trainMatrix1, valMatrix, trainLabels1, valLabels = train_test_split(mixedMatrix, mixedLabels, test_size = 0.1)\n",
    "trainMatrix, testMatrix, trainLabels, testLabels = train_test_split(trainMatrix1, trainLabels1, test_size = 0.1)\n",
    "\n",
    "numSig = len(signalMatrix)\n",
    "numBack = len(ttbarMatrix)\n",
    "totalEntries = numSig + numBack\n",
    "bias = numSig / (totalEntries)\n",
    "class_weight = {0: totalEntries/(2*numBack), 1: totalEntries/(2*numSig)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc16e_signal2625\n",
      "mc16e_signal2375\n"
     ]
    }
   ],
   "source": [
    "print(trainMatrix.__getitem__(1))\n",
    "print(trainMatrix[0])\n",
    "#print(trainLabels)\n",
    "#print(testMatrix)\n",
    "#print(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(ID):\n",
    "    if(\"mc16e_signal\" in ID):\n",
    "        return 1\n",
    "    elif(\"mc16e_ttbar\" in ID):\n",
    "        return 0\n",
    "\n",
    "trainGenerator = DataGenerator(mixedMatrix, getLabel, useWeightObj=True, weightObj=class_weight, batch_size=256, dim=14, n_channels=1, n_classes=2, shuffle=True)\n",
    "\n",
    "valGenerator = DataGenerator(valMatrix, getLabel, useWeightObj=True, weightObj=class_weight, batch_size=256, dim=14, n_channels=1, n_classes=2, shuffle=True)\n",
    "\n",
    "testGenerator = DataGenerator(testMatrix, getLabel, useWeightObj=True, weightObj=class_weight, batch_size=256, dim=14, n_channels=1, n_classes=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 1.71191491, -1.33080344, -1.54720405, ...,  1.46869655,\n",
      "        -1.41633862,  0.24643954],\n",
      "       [-0.15393907,  1.34855147,  1.46653672, ...,  0.4134363 ,\n",
      "        -1.6501906 , -1.06153034],\n",
      "       [-0.79585039, -0.48221681,  0.22366738, ...,  0.11174436,\n",
      "        -0.28008785,  0.39952099],\n",
      "       ...,\n",
      "       [-0.16902344,  0.88164584,  0.01270946, ...,  0.26348539,\n",
      "        -0.14371319, -0.41589282],\n",
      "       [-0.30803758,  2.10987734, -0.73907771, ...,  1.51598418,\n",
      "        -0.13701495, -0.36915139],\n",
      "       [ 0.09777169,  0.92210592,  1.22192682, ..., -0.96548007,\n",
      "         1.51773151,  1.03452487]]), array([[0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       ...,\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.]], dtype=float32), array([0.00432557, 0.00756403, 0.10269706, ..., 0.09471179, 0.067259  ,\n",
      "       0.00787717]))\n",
      "[[ 1.71191491 -1.33080344 -1.54720405 ...  1.46869655 -1.41633862\n",
      "   0.24643954]\n",
      " [-0.15393907  1.34855147  1.46653672 ...  0.4134363  -1.6501906\n",
      "  -1.06153034]\n",
      " [-0.79585039 -0.48221681  0.22366738 ...  0.11174436 -0.28008785\n",
      "   0.39952099]\n",
      " ...\n",
      " [-0.16902344  0.88164584  0.01270946 ...  0.26348539 -0.14371319\n",
      "  -0.41589282]\n",
      " [-0.30803758  2.10987734 -0.73907771 ...  1.51598418 -0.13701495\n",
      "  -0.36915139]\n",
      " [ 0.09777169  0.92210592  1.22192682 ... -0.96548007  1.51773151\n",
      "   1.03452487]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "[0.00432557 0.00756403 0.10269706 ... 0.09471179 0.067259   0.00787717]\n"
     ]
    }
   ],
   "source": [
    "print(trainGenerator[0])\n",
    "print(trainGenerator[0][0])\n",
    "print(trainGenerator[0][1])\n",
    "print(trainGenerator[0][2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 20)                280       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322\n",
      "Trainable params: 322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'),\n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.AUC(name='prc', curve='PR'),\n",
    "]\n",
    "\n",
    "nn_model = get_model(METRICS, (13,), bias)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403 - tp: 2616.0000 - fp: 3451.0000 - tn: 2549.0000 - fn: 3384.0000 - accuracy: 0.4304 - precision: 0.4312 - recall: 0.4360 - auc: 0.3942 - prc: 0.4176WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 1: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 5s 677ms/step - loss: 0.0403 - tp: 2616.0000 - fp: 3451.0000 - tn: 2549.0000 - fn: 3384.0000 - accuracy: 0.4304 - precision: 0.4312 - recall: 0.4360 - auc: 0.3942 - prc: 0.4176\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400 - tp: 2637.0000 - fp: 3428.0000 - tn: 2572.0000 - fn: 3363.0000 - accuracy: 0.4341 - precision: 0.4348 - recall: 0.4395 - auc: 0.3973 - prc: 0.4192WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 2: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 671ms/step - loss: 0.0400 - tp: 2637.0000 - fp: 3428.0000 - tn: 2572.0000 - fn: 3363.0000 - accuracy: 0.4341 - precision: 0.4348 - recall: 0.4395 - auc: 0.3973 - prc: 0.4192\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403 - tp: 2628.0000 - fp: 3408.0000 - tn: 2592.0000 - fn: 3372.0000 - accuracy: 0.4350 - precision: 0.4354 - recall: 0.4380 - auc: 0.3993 - prc: 0.4204WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 3: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0403 - tp: 2628.0000 - fp: 3408.0000 - tn: 2592.0000 - fn: 3372.0000 - accuracy: 0.4350 - precision: 0.4354 - recall: 0.4380 - auc: 0.3993 - prc: 0.4204\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403 - tp: 2620.0000 - fp: 3428.0000 - tn: 2572.0000 - fn: 3380.0000 - accuracy: 0.4327 - precision: 0.4332 - recall: 0.4367 - auc: 0.3969 - prc: 0.4189WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 4: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.0403 - tp: 2620.0000 - fp: 3428.0000 - tn: 2572.0000 - fn: 3380.0000 - accuracy: 0.4327 - precision: 0.4332 - recall: 0.4367 - auc: 0.3969 - prc: 0.4189\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0401 - tp: 2632.0000 - fp: 3436.0000 - tn: 2564.0000 - fn: 3368.0000 - accuracy: 0.4330 - precision: 0.4338 - recall: 0.4387 - auc: 0.3976 - prc: 0.4195WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 5: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 0.0401 - tp: 2632.0000 - fp: 3436.0000 - tn: 2564.0000 - fn: 3368.0000 - accuracy: 0.4330 - precision: 0.4338 - recall: 0.4387 - auc: 0.3976 - prc: 0.4195\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0401 - tp: 2609.0000 - fp: 3436.0000 - tn: 2564.0000 - fn: 3391.0000 - accuracy: 0.4311 - precision: 0.4316 - recall: 0.4348 - auc: 0.3955 - prc: 0.4182WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 6: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 0.0401 - tp: 2609.0000 - fp: 3436.0000 - tn: 2564.0000 - fn: 3391.0000 - accuracy: 0.4311 - precision: 0.4316 - recall: 0.4348 - auc: 0.3955 - prc: 0.4182\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400 - tp: 2646.0000 - fp: 3420.0000 - tn: 2580.0000 - fn: 3354.0000 - accuracy: 0.4355 - precision: 0.4362 - recall: 0.4410 - auc: 0.3995 - prc: 0.4206WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 7: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 691ms/step - loss: 0.0400 - tp: 2646.0000 - fp: 3420.0000 - tn: 2580.0000 - fn: 3354.0000 - accuracy: 0.4355 - precision: 0.4362 - recall: 0.4410 - auc: 0.3995 - prc: 0.4206\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400 - tp: 2625.0000 - fp: 3400.0000 - tn: 2600.0000 - fn: 3375.0000 - accuracy: 0.4354 - precision: 0.4357 - recall: 0.4375 - auc: 0.3990 - prc: 0.4201WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 8: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.0400 - tp: 2625.0000 - fp: 3400.0000 - tn: 2600.0000 - fn: 3375.0000 - accuracy: 0.4354 - precision: 0.4357 - recall: 0.4375 - auc: 0.3990 - prc: 0.4201\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400 - tp: 2642.0000 - fp: 3430.0000 - tn: 2570.0000 - fn: 3358.0000 - accuracy: 0.4343 - precision: 0.4351 - recall: 0.4403 - auc: 0.3959 - prc: 0.4184WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 9: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 831ms/step - loss: 0.0400 - tp: 2642.0000 - fp: 3430.0000 - tn: 2570.0000 - fn: 3358.0000 - accuracy: 0.4343 - precision: 0.4351 - recall: 0.4403 - auc: 0.3959 - prc: 0.4184\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400 - tp: 2653.0000 - fp: 3422.0000 - tn: 2578.0000 - fn: 3347.0000 - accuracy: 0.4359 - precision: 0.4367 - recall: 0.4422 - auc: 0.4003 - prc: 0.4207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 10: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 765ms/step - loss: 0.0400 - tp: 2653.0000 - fp: 3422.0000 - tn: 2578.0000 - fn: 3347.0000 - accuracy: 0.4359 - precision: 0.4367 - recall: 0.4422 - auc: 0.4003 - prc: 0.4207\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0399 - tp: 2635.0000 - fp: 3432.0000 - tn: 2568.0000 - fn: 3365.0000 - accuracy: 0.4336 - precision: 0.4343 - recall: 0.4392 - auc: 0.3971 - prc: 0.4191WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 11: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 490ms/step - loss: 0.0399 - tp: 2635.0000 - fp: 3432.0000 - tn: 2568.0000 - fn: 3365.0000 - accuracy: 0.4336 - precision: 0.4343 - recall: 0.4392 - auc: 0.3971 - prc: 0.4191\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0402 - tp: 2643.0000 - fp: 3429.0000 - tn: 2571.0000 - fn: 3357.0000 - accuracy: 0.4345 - precision: 0.4353 - recall: 0.4405 - auc: 0.3995 - prc: 0.4203WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 12: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 683ms/step - loss: 0.0402 - tp: 2643.0000 - fp: 3429.0000 - tn: 2571.0000 - fn: 3357.0000 - accuracy: 0.4345 - precision: 0.4353 - recall: 0.4405 - auc: 0.3995 - prc: 0.4203\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403 - tp: 2630.0000 - fp: 3424.0000 - tn: 2576.0000 - fn: 3370.0000 - accuracy: 0.4338 - precision: 0.4344 - recall: 0.4383 - auc: 0.3974 - prc: 0.4184WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 13: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 0.0403 - tp: 2630.0000 - fp: 3424.0000 - tn: 2576.0000 - fn: 3370.0000 - accuracy: 0.4338 - precision: 0.4344 - recall: 0.4383 - auc: 0.3974 - prc: 0.4184\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0402 - tp: 2631.0000 - fp: 3413.0000 - tn: 2587.0000 - fn: 3369.0000 - accuracy: 0.4348 - precision: 0.4353 - recall: 0.4385 - auc: 0.3988 - prc: 0.4200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 14: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 646ms/step - loss: 0.0402 - tp: 2631.0000 - fp: 3413.0000 - tn: 2587.0000 - fn: 3369.0000 - accuracy: 0.4348 - precision: 0.4353 - recall: 0.4385 - auc: 0.3988 - prc: 0.4200\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0402 - tp: 2629.0000 - fp: 3441.0000 - tn: 2559.0000 - fn: 3371.0000 - accuracy: 0.4323 - precision: 0.4331 - recall: 0.4382 - auc: 0.3958 - prc: 0.4186WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 15: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0402 - tp: 2629.0000 - fp: 3441.0000 - tn: 2559.0000 - fn: 3371.0000 - accuracy: 0.4323 - precision: 0.4331 - recall: 0.4382 - auc: 0.3958 - prc: 0.4186\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0399 - tp: 2616.0000 - fp: 3446.0000 - tn: 2554.0000 - fn: 3384.0000 - accuracy: 0.4308 - precision: 0.4315 - recall: 0.4360 - auc: 0.3952 - prc: 0.4181WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 16: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.0399 - tp: 2616.0000 - fp: 3446.0000 - tn: 2554.0000 - fn: 3384.0000 - accuracy: 0.4308 - precision: 0.4315 - recall: 0.4360 - auc: 0.3952 - prc: 0.4181\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403 - tp: 2625.0000 - fp: 3428.0000 - tn: 2572.0000 - fn: 3375.0000 - accuracy: 0.4331 - precision: 0.4337 - recall: 0.4375 - auc: 0.3971 - prc: 0.4190WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 17: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 3s 992ms/step - loss: 0.0403 - tp: 2625.0000 - fp: 3428.0000 - tn: 2572.0000 - fn: 3375.0000 - accuracy: 0.4331 - precision: 0.4337 - recall: 0.4375 - auc: 0.3971 - prc: 0.4190\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400 - tp: 2633.0000 - fp: 3431.0000 - tn: 2569.0000 - fn: 3367.0000 - accuracy: 0.4335 - precision: 0.4342 - recall: 0.4388 - auc: 0.3975 - prc: 0.4187WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 18: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.0400 - tp: 2633.0000 - fp: 3431.0000 - tn: 2569.0000 - fn: 3367.0000 - accuracy: 0.4335 - precision: 0.4342 - recall: 0.4388 - auc: 0.3975 - prc: 0.4187\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0399 - tp: 2643.0000 - fp: 3425.0000 - tn: 2575.0000 - fn: 3357.0000 - accuracy: 0.4348 - precision: 0.4356 - recall: 0.4405 - auc: 0.3984 - prc: 0.4196WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 19: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 0.0399 - tp: 2643.0000 - fp: 3425.0000 - tn: 2575.0000 - fn: 3357.0000 - accuracy: 0.4348 - precision: 0.4356 - recall: 0.4405 - auc: 0.3984 - prc: 0.4196\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403 - tp: 2630.0000 - fp: 3421.0000 - tn: 2579.0000 - fn: 3370.0000 - accuracy: 0.4341 - precision: 0.4346 - recall: 0.4383 - auc: 0.3982 - prc: 0.4192WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 20: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 0.0403 - tp: 2630.0000 - fp: 3421.0000 - tn: 2579.0000 - fn: 3370.0000 - accuracy: 0.4341 - precision: 0.4346 - recall: 0.4383 - auc: 0.3982 - prc: 0.4192\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0404 - tp: 2603.0000 - fp: 3421.0000 - tn: 2579.0000 - fn: 3397.0000 - accuracy: 0.4318 - precision: 0.4321 - recall: 0.4338 - auc: 0.3964 - prc: 0.4185WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 21: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 0.0404 - tp: 2603.0000 - fp: 3421.0000 - tn: 2579.0000 - fn: 3397.0000 - accuracy: 0.4318 - precision: 0.4321 - recall: 0.4338 - auc: 0.3964 - prc: 0.4185\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0402 - tp: 2634.0000 - fp: 3411.0000 - tn: 2589.0000 - fn: 3366.0000 - accuracy: 0.4353 - precision: 0.4357 - recall: 0.4390 - auc: 0.3996 - prc: 0.4201WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,tp,fp,tn,fn,accuracy,precision,recall,auc,prc\n",
      "\n",
      "Epoch 22: saving model to checkpoint.ckpt\n",
      "3/3 [==============================] - 2s 734ms/step - loss: 0.0402 - tp: 2634.0000 - fp: 3411.0000 - tn: 2589.0000 - fn: 3366.0000 - accuracy: 0.4353 - precision: 0.4357 - recall: 0.4390 - auc: 0.3996 - prc: 0.4201\n",
      "Epoch 23/1000\n",
      "1/3 [=========>....................] - ETA: 1s - loss: 0.0399 - tp: 867.0000 - fp: 1154.0000 - tn: 846.0000 - fn: 1133.0000 - accuracy: 0.4283 - precision: 0.4290 - recall: 0.4335 - auc: 0.3940 - prc: 0.4174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stopping \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m cp_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(filepath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpoint.ckpt\u001b[39m\u001b[39m\"\u001b[39m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m nnfit \u001b[39m=\u001b[39m nn_model\u001b[39m.\u001b[39;49mfit(trainGenerator, epochs \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping, cp_callback])\n\u001b[1;32m      6\u001b[0m \u001b[39m#y_scores = nn_model.predict(scaled_test_df)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m nn_model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39msample_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoint.ckpt\", save_weights_only=True, verbose=1)\n",
    "\n",
    "nnfit = nn_model.fit(trainGenerator, epochs = 1000, callbacks=[early_stopping, cp_callback])\n",
    "\n",
    "#y_scores = nn_model.predict(scaled_test_df)\n",
    "nn_model.save('sample_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mueta_cand: 0.16002351\n",
      "muphi_cand: 0.18046325\n",
      "ljet_pt_cand: 0.19509485\n",
      "met_phi: 0.21438567\n",
      "mass_mj: 0.28379577\n",
      "mupt_cand: 0.29799345\n",
      "ljet_phi_cand: 0.30252308\n",
      "mass_T: 0.31369695\n",
      "ljet_eta_cand: 0.35461175\n",
      "dR_values_cand: 0.3590666\n",
      "pt_higgs: 0.3704209\n",
      "ljet_mass_cand: 0.37326616\n",
      "met_met: 0.401074\n"
     ]
    }
   ],
   "source": [
    "def hiWeightVars(model, inVars):\n",
    "    model_weights = model.layers[0].get_weights()[0]\n",
    "    if('classification' in inVars):\n",
    "        inVars.remove('classification')\n",
    "    if('weight' in inVars):\n",
    "        inVars.remove('weight')\n",
    "    model_weights = [np.mean([abs(weight) for weight in weights]) for weights in model_weights]\n",
    "    \n",
    "    a = zip(model_weights, inVars)\n",
    "    b = sorted(a)\n",
    "    model_weights, inVars = zip(*b)\n",
    "\n",
    "    for i in range(len(model_weights)):\n",
    "        print(str(inVars[i]) + \": \" + str(model_weights[i]))\n",
    "\n",
    "hiWeightVars(nn_model, train_variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "[[0.50128454 0.4963157 ]\n",
      " [0.97932845 0.9771987 ]\n",
      " [0.8643316  0.7468014 ]\n",
      " [0.91545    0.6924078 ]\n",
      " [0.8394927  0.687058  ]\n",
      " [0.83755374 0.5175192 ]\n",
      " [0.640758   0.6465434 ]\n",
      " [0.90286225 0.6040088 ]\n",
      " [0.87116736 0.5244425 ]\n",
      " [0.9325398  0.57892627]\n",
      " [0.6024543  0.46521288]\n",
      " [0.76312405 0.71444637]\n",
      " [0.85875124 0.8177056 ]\n",
      " [0.71272844 0.70370287]\n",
      " [0.8300963  0.53513   ]\n",
      " [0.787357   0.38734102]\n",
      " [0.88638246 0.6541037 ]\n",
      " [0.63799673 0.47185093]\n",
      " [0.53652894 0.5339829 ]\n",
      " [0.8579109  0.42137048]\n",
      " [0.52639204 0.5184237 ]\n",
      " [0.76835924 0.52304804]\n",
      " [0.8577261  0.8710656 ]\n",
      " [0.78026605 0.75332105]\n",
      " [0.7701825  0.7484358 ]\n",
      " [0.816429   0.5475472 ]\n",
      " [0.50128454 0.4963157 ]\n",
      " [0.8160762  0.59829277]\n",
      " [0.79660636 0.76533294]\n",
      " [0.50128454 0.4963157 ]\n",
      " [0.8438023  0.83609354]\n",
      " [0.89019257 0.7804105 ]\n",
      " [0.7575612  0.59437925]\n",
      " [0.7380238  0.47398674]\n",
      " [0.86866474 0.67824876]\n",
      " [0.82038105 0.6802491 ]\n",
      " [0.6259334  0.45129293]\n",
      " [0.8167648  0.544914  ]\n",
      " [0.68994    0.3547255 ]\n",
      " [0.89389634 0.7446751 ]\n",
      " [0.885892   0.55585593]\n",
      " [0.89591455 0.5076305 ]\n",
      " [0.5972423  0.46941942]\n",
      " [0.8098364  0.5654721 ]\n",
      " [0.8948413  0.26891282]\n",
      " [0.74839044 0.4749942 ]\n",
      " [0.90358025 0.64780736]\n",
      " [0.7700794  0.41456962]\n",
      " [0.8676208  0.8368849 ]\n",
      " [0.793265   0.797525  ]\n",
      " [0.63112557 0.37509704]\n",
      " [0.8719856  0.36171928]\n",
      " [0.8664018  0.8360681 ]\n",
      " [0.78347474 0.7289608 ]\n",
      " [0.6888259  0.49673486]\n",
      " [0.84651345 0.61571056]\n",
      " [0.74978596 0.76247346]\n",
      " [0.79123557 0.28573814]\n",
      " [0.7995883  0.6316716 ]\n",
      " [0.9290246  0.44152284]\n",
      " [0.8862357  0.49585253]\n",
      " [0.82473505 0.7930921 ]\n",
      " [0.6411082  0.3878281 ]\n",
      " [0.70656496 0.5168575 ]\n",
      " [0.8478861  0.46685964]\n",
      " [0.7134574  0.5216048 ]\n",
      " [0.85780233 0.23976916]\n",
      " [0.8888106  0.4865687 ]\n",
      " [0.9414592  0.8599903 ]\n",
      " [0.6084653  0.37740314]\n",
      " [0.89132166 0.7375345 ]\n",
      " [0.88604325 0.23873971]\n",
      " [0.6041408  0.46128663]\n",
      " [0.7656011  0.33339366]\n",
      " [0.8928222  0.45452452]\n",
      " [0.50128454 0.4963157 ]\n",
      " [0.50128454 0.4963157 ]\n",
      " [0.745769   0.38127896]\n",
      " [0.8062575  0.7833784 ]\n",
      " [0.7036779  0.36157084]\n",
      " [0.8948148  0.34757513]\n",
      " [0.8902503  0.5599692 ]\n",
      " [0.87232745 0.79657876]\n",
      " [0.55649483 0.47949326]\n",
      " [0.6782668  0.5714964 ]\n",
      " [0.7582074  0.70974576]\n",
      " [0.8466497  0.6312851 ]\n",
      " [0.72141427 0.620223  ]\n",
      " [0.9046448  0.4977251 ]\n",
      " [0.89125025 0.7167941 ]\n",
      " [0.7681508  0.7378651 ]\n",
      " [0.7426254  0.43361634]\n",
      " [0.9503155  0.87041426]\n",
      " [0.7296901  0.5188727 ]\n",
      " [0.50128454 0.4963157 ]\n",
      " [0.91139215 0.9016937 ]\n",
      " [0.92360485 0.8008892 ]\n",
      " [0.76047474 0.5910451 ]\n",
      " [0.6176673  0.48320094]\n",
      " [0.90715116 0.9127885 ]\n",
      " [0.8362613  0.5778312 ]\n",
      " [0.581033   0.5658871 ]\n",
      " [0.7863378  0.53586996]\n",
      " [0.8950763  0.21828073]\n",
      " [0.89043635 0.8255826 ]\n",
      " [0.83182037 0.6923281 ]\n",
      " [0.6319839  0.45578313]\n",
      " [0.7372925  0.50812536]\n",
      " [0.9329773  0.71979165]\n",
      " [0.5650765  0.5525845 ]\n",
      " [0.7912689  0.5862774 ]\n",
      " [0.7290065  0.51627016]\n",
      " [0.781119   0.7796231 ]\n",
      " [0.6952686  0.6809084 ]\n",
      " [0.84119487 0.69301903]\n",
      " [0.5666176  0.48765355]\n",
      " [0.9233576  0.9130175 ]\n",
      " [0.8996274  0.28305173]\n",
      " [0.82635003 0.81183463]\n",
      " [0.8591746  0.48767436]\n",
      " [0.7875626  0.47835922]\n",
      " [0.82639897 0.58260953]\n",
      " [0.7632897  0.5893618 ]\n",
      " [0.7758731  0.7706623 ]\n",
      " [0.8703194  0.80679023]\n",
      " [0.84889996 0.29195625]\n",
      " [0.6674501  0.70743746]\n",
      " [0.57573664 0.5142016 ]\n",
      " [0.7967744  0.7597212 ]\n",
      " [0.6957088  0.55128783]\n",
      " [0.78349495 0.298869  ]\n",
      " [0.93764496 0.94553846]\n",
      " [0.6649524  0.44658914]\n",
      " [0.7835711  0.75268036]\n",
      " [0.8712665  0.6437444 ]\n",
      " [0.7326849  0.36778048]\n",
      " [0.8967555  0.8914603 ]\n",
      " [0.9086154  0.28727087]\n",
      " [0.5124186  0.41696215]\n",
      " [0.65429    0.6114582 ]\n",
      " [0.928221   0.90319836]\n",
      " [0.72911483 0.52026474]\n",
      " [0.8888196  0.64396024]\n",
      " [0.6894759  0.68326586]\n",
      " [0.9184962  0.9197376 ]\n",
      " [0.88872916 0.4562328 ]\n",
      " [0.89364034 0.3590555 ]\n",
      " [0.63896054 0.43465403]\n",
      " [0.8354356  0.8197218 ]\n",
      " [0.64044195 0.35261792]\n",
      " [0.7101757  0.69354135]\n",
      " [0.8535093  0.4554739 ]\n",
      " [0.86826277 0.8456809 ]\n",
      " [0.8822392  0.87109196]\n",
      " [0.77819455 0.43015656]\n",
      " [0.60621285 0.5907233 ]\n",
      " [0.8593726  0.5612142 ]\n",
      " [0.85214996 0.617515  ]\n",
      " [0.8753513  0.43085146]\n",
      " [0.8330887  0.65933764]\n",
      " [0.8025176  0.65843606]\n",
      " [0.8669003  0.38424727]\n",
      " [0.80654734 0.72700197]\n",
      " [0.9102857  0.638327  ]\n",
      " [0.82767326 0.703658  ]\n",
      " [0.8942628  0.73728037]\n",
      " [0.82069606 0.7999322 ]\n",
      " [0.91068846 0.35689148]\n",
      " [0.7432742  0.5319991 ]\n",
      " [0.84617966 0.347013  ]\n",
      " [0.83857834 0.80701345]\n",
      " [0.731206   0.39005977]\n",
      " [0.72265667 0.50232005]\n",
      " [0.8630532  0.27576363]\n",
      " [0.8129589  0.79742455]\n",
      " [0.8568406  0.2259517 ]\n",
      " [0.83537346 0.84854484]\n",
      " [0.9147899  0.60658044]\n",
      " [0.8089962  0.82074976]\n",
      " [0.89342636 0.19717441]\n",
      " [0.5172726  0.5103898 ]\n",
      " [0.86443555 0.6332665 ]\n",
      " [0.8274673  0.6900197 ]\n",
      " [0.7780459  0.7411019 ]\n",
      " [0.8014565  0.8332839 ]\n",
      " [0.93335426 0.68020135]\n",
      " [0.8351823  0.4870548 ]\n",
      " [0.85446215 0.75508356]\n",
      " [0.5969779  0.50951433]\n",
      " [0.68598646 0.68170905]\n",
      " [0.7585663  0.753544  ]\n",
      " [0.68580025 0.64736694]\n",
      " [0.5209804  0.5136556 ]\n",
      " [0.7045775  0.6868036 ]\n",
      " [0.8545807  0.81889665]\n",
      " [0.8411057  0.42684844]\n",
      " [0.9166831  0.56269014]\n",
      " [0.5829953  0.6019445 ]\n",
      " [0.9277082  0.9185235 ]\n",
      " [0.9462469  0.55948496]\n",
      " [0.67678267 0.43582937]\n",
      " [0.9164965  0.55670226]\n",
      " [0.57453406 0.36500522]\n",
      " [0.8599044  0.7178086 ]\n",
      " [0.6009863  0.58447504]\n",
      " [0.8981117  0.7288563 ]\n",
      " [0.8933011  0.87999725]\n",
      " [0.7051625  0.28625387]\n",
      " [0.6572568  0.63499546]\n",
      " [0.72393423 0.69766   ]\n",
      " [0.50128454 0.4963157 ]\n",
      " [0.7781956  0.62885505]\n",
      " [0.8935689  0.69156355]\n",
      " [0.7377402  0.5864048 ]\n",
      " [0.7342634  0.77207184]\n",
      " [0.82676613 0.4698353 ]\n",
      " [0.62675166 0.65733135]\n",
      " [0.8456671  0.34476373]\n",
      " [0.6210136  0.4493653 ]\n",
      " [0.7928336  0.25249887]\n",
      " [0.7909859  0.50311714]\n",
      " [0.90062    0.91275656]\n",
      " [0.89886206 0.4236603 ]\n",
      " [0.9157454  0.89582145]\n",
      " [0.71522045 0.66299796]\n",
      " [0.7648698  0.30931932]\n",
      " [0.6239016  0.3009128 ]\n",
      " [0.90092427 0.9092257 ]\n",
      " [0.67307043 0.6572519 ]\n",
      " [0.8981262  0.30210677]\n",
      " [0.774798   0.4073722 ]\n",
      " [0.78897524 0.77590936]\n",
      " [0.55833554 0.5702541 ]\n",
      " [0.87282306 0.49584454]\n",
      " [0.8131277  0.7871947 ]\n",
      " [0.56758004 0.47608206]\n",
      " [0.9405356  0.27559894]\n",
      " [0.80316037 0.8187182 ]\n",
      " [0.80015767 0.20118998]\n",
      " [0.81319714 0.5173699 ]\n",
      " [0.57351786 0.546884  ]\n",
      " [0.8845357  0.4199648 ]\n",
      " [0.69278353 0.63585913]\n",
      " [0.81884706 0.5936094 ]\n",
      " [0.8109108  0.51081353]\n",
      " [0.7599318  0.3640494 ]\n",
      " [0.9025114  0.7690844 ]\n",
      " [0.812187   0.47965643]\n",
      " [0.7061652  0.50982815]\n",
      " [0.6087357  0.62077785]\n",
      " [0.9328899  0.40795934]\n",
      " [0.8217196  0.7537346 ]\n",
      " [0.8502789  0.5092672 ]\n",
      " [0.8100941  0.34222335]\n",
      " [0.7997117  0.5807573 ]\n",
      " [0.52367175 0.5253784 ]]\n"
     ]
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([nn_model, tf.keras.layers.Softmax()])\n",
    "predictions = nn_model.predict(testGenerator[0][0])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_model = get_model((14,))\n",
    "# #fit the model to train on all but the last column\n",
    "#print(\"MATT, FITTING MODEL\")\n",
    "#callback = LearningRateScheduler(custom_LearningRate_schedular)\n",
    "# print(train_dataset[:,train_dataset.shape[1]-1 : train_dataset.shape[1]])\n",
    "#nn_fit = nn_model.fit(train_dataset[:, 0:train_dataset.shape[1]-1], train_output, epochs=500, batch_size = 500, validation_data=(val_dataset[:, 0:train_dataset.shape[1]-1], val_output), sample_weight=train_dataset[:,train_dataset.shape[1]-1 : train_dataset.shape[1]], shuffle=True)\n",
    "# validation_data=(val_dataset[:, 0:train_dataset.shape[1]-1], val_output),\n",
    "# print(train_dataset[:,0:train_dataset.shape[1]-1])\n",
    "# nn_fit = nn_model.fit(train_dataset[:,0:train_dataset.shape[1]-1], train_output[:,0:0:train_dataset.shape[1]-1], epochs=70, batch_size=500, verbose=1, shuffle=True, validation_data=(val_dataset[:,0:train_dataset.shape[1]-1], val_output[:,0:train_dataset.shape[1]-1]), sample_weight=train_dataset[:,train_dataset.shape[1]-1:train_dataset.shape[1]])\n",
    "#print(\"MATT, MODEL FITTED\")\n",
    "#print(\"MATT, PREDICTING\")\n",
    "#y_scores = nn_model.predict(test_dataset[:, 0:train_dataset.shape[1]-1])\n",
    "\n",
    "\n",
    "\n",
    "#bdt_model = boosted_decision_tree()\n",
    "#print(\"MATT, FITTING MODEL\")\n",
    "#bdt_fit = bdt_model.fit(train_dataset[:, 0:train_dataset.shape[1]-1], train_output, sample_weight=train_dataset[:,train_dataset.shape[1]-1 : train_dataset.shape[1]])\n",
    "#print(\"MATT, MODEL FITTED\")\n",
    "#print(\"MATT, PREDICTING\")\n",
    "#bdt_y_scores = bdt_model.predict(test_dataset[:, 0:train_dataset.shape[1]-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class CIFAR10Sequence(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genObj = CIFAR10Sequence([1, 2, 3, 4, 5], [1, 4, 9, 16, 25], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingModel = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(1,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
